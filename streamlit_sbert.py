# -*- coding: utf-8 -*-
"""streamlit_sbert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14N83rlTIsuzbqFqRqMSWgAcPyM_R4h6X
"""

pip install streamlit sentence-transformers pandas

import streamlit as st
import pandas as pd
import torch
from sentence_transformers import SentenceTransformer, util

# Load the SBERT model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Upload files in Streamlit
st.title("üîç AI Resume Matcher")
st.write("Upload Resume and Job Description CSV files to match candidates with job roles.")

resume_file = st.file_uploader("Upload Resume CSV", type=["csv"])
jd_file = st.file_uploader("Upload Job Description CSV", type=["csv"])

if resume_file and jd_file:
    # Load CSV files
    df_resume = pd.read_csv(resume_file)
    df_jd = pd.read_csv(jd_file)

    # Preprocess column names
    df_resume.columns = df_resume.columns.str.strip()
    df_jd.columns = df_jd.columns.str.strip()

    # Ensure necessary columns exist
    if "Skills" not in df_resume.columns or "Keywords" not in df_jd.columns:
        st.error("CSV files must contain 'Skills' in Resume and 'Keywords' in JD.")
    else:
        # Fill missing values
        df_resume["Skills"] = df_resume["Skills"].fillna("").astype(str)
        df_jd["Keywords"] = df_jd["Keywords"].fillna("").astype(str)

        # Encode using SBERT
        resume_embeddings = model.encode(df_resume["Skills"].tolist(), convert_to_tensor=True)
        jd_embeddings = model.encode(df_jd["Keywords"].tolist(), convert_to_tensor=True)

        # Compute cosine similarity
        similarity_scores = util.cos_sim(resume_embeddings, jd_embeddings)

        # Convert similarity matrix to a DataFrame
        similarity_df = pd.DataFrame(similarity_scores.cpu().numpy(),
                                     index=df_resume["Resume ID"],
                                     columns=df_jd["Job Role"])

        # Find best matches
        top_matches = similarity_df.idxmax(axis=1)
        top_scores = similarity_df.max(axis=1)

        # Create results DataFrame
        results_df = pd.DataFrame({
            "Resume ID": df_resume["Resume ID"],
            "Best Matching Job Role": top_matches.values,
            "Similarity Score": top_scores.values
        })

        # Display results in Streamlit
        st.subheader("üîπ Matching Results")
        st.write(results_df)

        # Download results as CSV
        st.download_button(label="üì• Download Results", data=results_df.to_csv(index=False),
                           file_name="Resume_Job_Matching.csv", mime="text/csv")

!streamlit run app.py & npx localtunnel --port 8501